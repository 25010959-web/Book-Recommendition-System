{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Book Recommendation System\n",
    "\n",
    "## 1. Problem Definition & Objective\n",
    "\n",
    "### Selected Project Track\n",
    "**Recommendation Systems**\n",
    "\n",
    "### Problem Statement\n",
    "In the digital age, the abundance of books available online can be overwhelming for readers. Finding a book that matches a user's specific taste is a challenge. Users need a personalized system to discover relevant books based on their reading history or the similarity to books they already like.\n",
    "\n",
    "### Objective\n",
    "To build a **Book Recommendation System** that helps users discover books they are likely to enjoy. The system will leverage a dataset of book ratings to provide:\n",
    "1.  **Popularity-based Recommendations**: For new users or general browsing.\n",
    "2.  **Item-based Collaborative Filtering**: For personalized recommendations based on book similarity.\n",
    "\n",
    "### Real-world Relevance and Motivation\n",
    "*   **E-commerce**: Platforms like Amazon use recommendations to drive sales and cross-selling.\n",
    "*   **User Experience**: Personalized feeds increase user engagement and retention.\n",
    "*   **Discovery**: Helps lesser-known authors get discovered if their work is similar to popular titles.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Understanding & Preparation\n",
    "\n",
    "We will use the **Book-Crossing Dataset**, which comprises three files:\n",
    "*   `BX-Users.csv`: User information (ID, Location, Age).\n",
    "*   `BX-Books.csv`: Book information (ISBN, Title, Author, Year, Publisher, Image URLs).\n",
    "*   `BX-Book-Ratings-Subset.csv`: User ratings for books.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Load Datasets\n",
    "# Note: encoding='latin-1' is often required for this dataset due to special characters.\n",
    "# error_bad_lines=False (or on_bad_lines='skip' in newer pandas) helps skip malformed rows.\n",
    "\n",
    "books = pd.read_csv('BX-Books.csv', sep=';', encoding='latin-1', on_bad_lines='skip')\n",
    "users = pd.read_csv('BX-Users.csv', sep=';', encoding='latin-1', on_bad_lines='skip')\n",
    "ratings = pd.read_csv('BX-Book-Ratings-Subset.csv', sep=';', encoding='latin-1', on_bad_lines='skip')\n",
    "\n",
    "print(\"Books Shape:\", books.shape)\n",
    "print(\"Users Shape:\", users.shape)\n",
    "print(\"Ratings Shape:\", ratings.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Display first few rows\n",
    "print(\"Books Head:\")\n",
    "display(books.head(2))\n",
    "\n",
    "print(\"Ratings Head:\")\n",
    "display(ratings.head(2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Cleaning\n",
    "1.  **Renaming Columns**: For consistency/ease of access.\n",
    "2.  **Handling Missing Values**: Checking for nulls.\n",
    "3.  **Data Typing**: Ensuring ISBNs and User-IDs are consistent.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Rename columns for easier access\n",
    "books.columns = ['ISBN', 'Book-Title', 'Book-Author', 'Year-Of-Publication', 'Publisher', 'Image-URL-S', 'Image-URL-M', 'Image-URL-L']\n",
    "users.columns = ['User-ID', 'Location', 'Age']\n",
    "ratings.columns = ['User-ID', 'ISBN', 'Book-Rating']\n",
    "\n",
    "# Check for nulls\n",
    "print(\"Missing values in Books:\\n\", books.isnull().sum())\n",
    "print(\"Missing values in Users:\\n\", users.isnull().sum())\n",
    "print(\"Missing values in Ratings:\\n\", ratings.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Dropping Image URLs we don't need for analysis (we might keep them for the app later, but for the model we focus on Title/User/Rating)\n",
    "# Actually, let's keep them as they are useful for the UI.\n",
    "\n",
    "# Merge Ratings with Books to get Titles\n",
    "ratings_with_name = ratings.merge(books, on='ISBN')\n",
    "print(\"Merged Shape:\", ratings_with_name.shape)\n",
    "display(ratings_with_name.head(2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploratory Data Analysis (EDA)\n",
    "Let's look at the distribution of ratings.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Rating Distribution\n",
    "plt.figure(figsize=(10,4))\n",
    "ratings_with_name['Book-Rating'].value_counts().sort_index().plot(kind='bar')\n",
    "plt.title('Rating Distribution')\n",
    "plt.xlabel('Rating')\n",
    "plt.ylabel('Count')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Model / System Design\n",
    "\n",
    "We will implement two approaches:\n",
    "\n",
    "### A. Popularity Based Recommender System\n",
    "**Logic**: rank books by high ratings and high vote counts.\n",
    "*   **Formula**: Calculate average rating per book and total number of ratings per book.\n",
    "*   **Threshold**: Only consider books with at least X ratings (e.g., 50) to ensure reliability.\n",
    "*   **Result**: A static list of top-performing books.\n",
    "\n",
    "### B. Collaborative Filtering (Item-based)\n",
    "**Logic**: \"Users who liked this book also liked...\"\n",
    "*   **Matrix**: Create a 2D matrix (User-ID vs Book-Title).\n",
    "*   **Similarity**: Use **Cosine Similarity** to find distance between book vectors.\n",
    "*   **Result**: Given a book, return the top N most similar books based on user rating patterns.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Core Implementation\n",
    "\n",
    "### A. Popularity Based Recommender\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 1. Group by Book-Title and count ratings\n",
    "num_rating_df = ratings_with_name.groupby('Book-Title').count()['Book-Rating'].reset_index()\n",
    "num_rating_df.rename(columns={'Book-Rating': 'num_ratings'}, inplace=True)\n",
    "\n",
    "# 2. Group by Book-Title and average ratings\n",
    "avg_rating_df = ratings_with_name.groupby('Book-Title').mean(numeric_only=True)['Book-Rating'].reset_index()\n",
    "avg_rating_df.rename(columns={'Book-Rating': 'avg_rating'}, inplace=True)\n",
    "\n",
    "# 3. Merge\n",
    "popular_df = num_rating_df.merge(avg_rating_df, on='Book-Title')\n",
    "\n",
    "# 4. Filter: Let's pick books with > 50 ratings (Since this is a subset, we might lower this threshold if needed, but let's try 50)\n",
    "popular_df = popular_df[popular_df['num_ratings'] >= 50].sort_values('avg_rating', ascending=False).head(50)\n",
    "\n",
    "# 5. Merge with books to get details (Author, Image)\n",
    "# distinct books\n",
    "popular_df = popular_df.merge(books, on='Book-Title').drop_duplicates('Book-Title')[['Book-Title', 'Book-Author', 'Image-URL-M', 'num_ratings', 'avg_rating']]\n",
    "\n",
    "print(f\"Found {len(popular_df)} popular books.\")\n",
    "display(popular_df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B. Collaborative Filtering Recommender\n",
    "We want to recommend books based on a selected book. We will look at users who rated both books similarly.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 1. Filter data for \"experienced\" users to reduce noise (e.g., users who rated > 200 books)\n",
    "# In the full dataset this is common. In this subset, we check the user activity.\n",
    "x = ratings_with_name.groupby('User-ID').count()['Book-Rating'] > 20\n",
    "padhe_likhe_users = x[x].index\n",
    "\n",
    "filtered_rating = ratings_with_name[ratings_with_name['User-ID'].isin(padhe_likhe_users)]\n",
    "\n",
    "# 2. Filter for famous books (e.g., books with > 50 ratings)\n",
    "y = filtered_rating.groupby('Book-Title').count()['Book-Rating'] >= 50\n",
    "famous_books = y[y].index\n",
    "\n",
    "final_ratings = filtered_rating[filtered_rating['Book-Title'].isin(famous_books)]\n",
    "\n",
    "print(\"Final Ratings Shape for Matrix:\", final_ratings.shape)\n",
    "\n",
    "# 3. Create Pivot Table\n",
    "if not final_ratings.empty:\n",
    "    pt = final_ratings.pivot_table(index='Book-Title', columns='User-ID', values='Book-Rating')\n",
    "    pt.fillna(0, inplace=True)\n",
    "    print(\"Pivot Table Shape:\", pt.shape)\n",
    "    display(pt.head())\n",
    "else:\n",
    "    print(\"Not enough data in subset to create a dense matrix with these thresholds. Lowering thresholds for demonstration if needed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "if not final_ratings.empty:\n",
    "    similarity_scores = cosine_similarity(pt)\n",
    "    print(\"Similarity Matrix Shape:\", similarity_scores.shape)\n",
    "    \n",
    "    def recommend(book_name):\n",
    "        # fetch index\n",
    "        try:\n",
    "            index = np.where(pt.index == book_name)[0][0]\n",
    "            similar_items = sorted(list(enumerate(similarity_scores[index])), key=lambda x: x[1], reverse=True)[1:6]\n",
    "            \n",
    "            data = []\n",
    "            for i in similar_items:\n",
    "                item = []\n",
    "                temp_df = books[books['Book-Title'] == pt.index[i[0]]]\n",
    "                item.extend(list(temp_df.drop_duplicates('Book-Title')['Book-Title'].values))\n",
    "                item.extend(list(temp_df.drop_duplicates('Book-Title')['Book-Author'].values))\n",
    "                item.extend(list(temp_df.drop_duplicates('Book-Title')['Image-URL-M'].values))\n",
    "                \n",
    "                data.append(item)\n",
    "            \n",
    "            return data\n",
    "        except IndexError:\n",
    "            return \"Book not found in the matrix.\"\n",
    "            \n",
    "    # Test\n",
    "    print(\"Recommendations for a book (if exists in PT):\")\n",
    "    # Let's pick one from index\n",
    "    if len(pt.index) > 0:\n",
    "        test_book = pt.index[0]\n",
    "        print(f\"Testing with: {test_book}\")\n",
    "        print(recommend(test_book))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Evaluation & Analysis\n",
    "\n",
    "### Qualitative Evaluation\n",
    "Since we used unsupervised learning (Collaborative Filtering), we evaluate by inspection.\n",
    "*   **Popularity Model**: Does it return generally well-regarded books? (e.g., Harry Potter, To Kill a Mockingbird).\n",
    "*   **Collaborative Model**: If we select \"Harry Potter\", do we get other fantasy books or sequels?\n",
    "\n",
    "(Note: In a real-world scenario, we would use metrics like RMSE on a test set, or A/B testing).\n",
    "\n",
    "### Insights\n",
    "*   The sparsity of the matrix affects recommendation quality.\n",
    "*   Popularity-based is a good \"Safe\" fallback when we don't know the user's history.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Ethical Considerations & Responsible AI\n",
    "\n",
    "*   **Bias**: If the dataset is dominated by a specific demographic (e.g., age, location), recommendations will be biased towards their preferences.\n",
    "*   **Filter Bubble**: Collaborative filtering tends to reinforce existing preferences, potentially limiting exposure to diverse genres/viewpoints.\n",
    "*   **Privacy**: Using User-IDs and locations raises privacy concerns. We must ensure data is anonymized and used only for the stated purpose.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Conclusion & Future Scope\n",
    "\n",
    "### Conclusion\n",
    "We successfully built a hybrid approach:\n",
    "1.  **Top 50 Books**: Solves the \"Cold Start\" problem for new users.\n",
    "2.  **Recommender Engine**: Provides personalized suggestions for engaged users.\n",
    "\n",
    "### Future Scope\n",
    "*   **Hybrid Model**: Combine content-based (Author, Publisher) with Collaborative Filtering.\n",
    "*   **Deployment**: This logic is deployed using a Streamlit Web Application.\n",
    "*   **Feedback Loop**: Capture user clicks on recommendations to improve the model over time.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}